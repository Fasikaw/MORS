{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aim: convert spatially-distributed WFDEI forcing data to averaged lumped timeseries of Temperature and Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nadym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read basin shematization file\n",
    "nadym_coord = pd.read_csv('../../Schemes/drt_05_nadym.csv', usecols=[0, 1])\n",
    "nadym_coord.columns = ['lon','lat']\n",
    "#calculate weights of each cell for further weighted averaging\n",
    "nadym_coord['weights'] = (np.cos((nadym_coord['lat'] + 0.25)*np.pi/180) + np.cos((nadym_coord['lat'] - 0.25)*np.pi/180))\n",
    "nadym_coord['weights'] = nadym_coord['weights']/np.sum(nadym_coord['weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read WFDEI forcing data\n",
    "nadym_forc = pd.read_csv('../../Meteo_forcing_WFDEI/wfdei_for_nadym.csv', index_col=0, parse_dates=True)\n",
    "#cut necessary variables (Rainf, Snowf, Tair)\n",
    "nadym_rain = nadym_forc[['Rainf_'+str(point) for point in nadym_coord.index]]\n",
    "nadym_snow = nadym_forc[['Snowf_'+str(point) for point in nadym_coord.index]]\n",
    "nadym_temp = nadym_forc[['Tair_'+str(point) for point in nadym_coord.index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert precipitation (average rate mm/sec for 24 hours) to (sum of mm for whole day) \n",
    "#just multiply all values by 60sec*60min*24h\n",
    "nadym_rain = nadym_rain*(60*60*24)\n",
    "nadym_snow = nadym_snow*(60*60*24)\n",
    "#convert temperature from Kelvins to Celsius\n",
    "nadym_temp = nadym_temp-273.15\n",
    "#summarize rain and snow to one precipitation parameter\n",
    "nadym_prec = nadym_rain.add(nadym_snow.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#weighted averaging (sum of weight_i*value_i)\n",
    "nadym_prec_avrg = nadym_prec.mul(nadym_coord['weights'].values, axis=1).sum(axis=1)\n",
    "nadym_temp_avrg = nadym_temp.mul(nadym_coord['weights'].values, axis=1).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#wrap up results to .csv file\n",
    "pd.DataFrame({'Temp': nadym_temp_avrg, 'Prec': nadym_prec_avrg}, index=nadym_temp_avrg.index).to_csv('nadym_avrg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#read basin shematization file\n",
    "pur_coord = pd.read_csv('../../Schemes/drt_05_pur.csv', usecols=[0, 1])\n",
    "pur_coord.columns = ['lon','lat']\n",
    "#calculate weights of each cell for further weighted averaging\n",
    "pur_coord['weights'] = (np.cos((pur_coord['lat'] + 0.25)*np.pi/180) + np.cos((pur_coord['lat'] - 0.25)*np.pi/180))\n",
    "pur_coord['weights'] = pur_coord['weights']/np.sum(pur_coord['weights'])\n",
    "\n",
    "#read WFDEI forcing data\n",
    "pur_forc = pd.read_csv('../../Meteo_forcing_WFDEI/wfdei_for_pur.csv', index_col=0, parse_dates=True)\n",
    "#cut necessary variables (Rainf, Snowf, Tair)\n",
    "pur_rain = pur_forc[['Rainf_'+str(point) for point in pur_coord.index]]\n",
    "pur_snow = pur_forc[['Snowf_'+str(point) for point in pur_coord.index]]\n",
    "pur_temp = pur_forc[['Tair_'+str(point) for point in pur_coord.index]]\n",
    "\n",
    "#convert precipitation (average rate mm/sec for 24 hours) to (sum of mm for whole day) \n",
    "#just multiply all values by 60sec*60min*24h\n",
    "pur_rain = pur_rain*(60*60*24)\n",
    "pur_snow = pur_snow*(60*60*24)\n",
    "#convert temperature from Kelvins to Celsius\n",
    "pur_temp = pur_temp-273.15\n",
    "#summarize rain and snow to one precipitation parameter\n",
    "pur_prec = pur_rain.add(pur_snow.values)\n",
    "\n",
    "#weighted averaging (sum of weight_i*value_i)\n",
    "pur_prec_avrg = pur_prec.mul(pur_coord['weights'].values, axis=1).sum(axis=1)\n",
    "pur_temp_avrg = pur_temp.mul(pur_coord['weights'].values, axis=1).sum(axis=1)\n",
    "\n",
    "#wrap up results to .csv file\n",
    "pd.DataFrame({'Temp': pur_temp_avrg, 'Prec': pur_prec_avrg}, index=pur_temp_avrg.index).to_csv('pur_avrg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#read basin shematization file\n",
    "taz_coord = pd.read_csv('../../Schemes/drt_05_taz.csv', usecols=[0, 1])\n",
    "taz_coord.columns = ['lon','lat']\n",
    "#calculate weights of each cell for further weighted averaging\n",
    "taz_coord['weights'] = (np.cos((taz_coord['lat'] + 0.25)*np.pi/180) + np.cos((taz_coord['lat'] - 0.25)*np.pi/180))\n",
    "taz_coord['weights'] = taz_coord['weights']/np.sum(taz_coord['weights'])\n",
    "\n",
    "#read WFDEI forcing data\n",
    "taz_forc = pd.read_csv('../../Meteo_forcing_WFDEI/wfdei_for_taz.csv', index_col=0, parse_dates=True)\n",
    "#cut necessary variables (Rainf, Snowf, Tair)\n",
    "taz_rain = taz_forc[['Rainf_'+str(point) for point in taz_coord.index]]\n",
    "taz_snow = taz_forc[['Snowf_'+str(point) for point in taz_coord.index]]\n",
    "taz_temp = taz_forc[['Tair_'+str(point) for point in taz_coord.index]]\n",
    "\n",
    "#convert precipitation (average rate mm/sec for 24 hours) to (sum of mm for whole day) \n",
    "#just multiply all values by 60sec*60min*24h\n",
    "taz_rain = taz_rain*(60*60*24)\n",
    "taz_snow = taz_snow*(60*60*24)\n",
    "#convert temperature from Kelvins to Celsius\n",
    "taz_temp = taz_temp-273.15\n",
    "#summarize rain and snow to one precipitation parameter\n",
    "taz_prec = taz_rain.add(taz_snow.values)\n",
    "\n",
    "#weighted averaging (sum of weight_i*value_i)\n",
    "taz_prec_avrg = taz_prec.mul(taz_coord['weights'].values, axis=1).sum(axis=1)\n",
    "taz_temp_avrg = taz_temp.mul(taz_coord['weights'].values, axis=1).sum(axis=1)\n",
    "\n",
    "#wrap up results to .csv file\n",
    "pd.DataFrame({'Temp': taz_temp_avrg, 'Prec': taz_prec_avrg}, index=taz_temp_avrg.index).to_csv('taz_avrg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
